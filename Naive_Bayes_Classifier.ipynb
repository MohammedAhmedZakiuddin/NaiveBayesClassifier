{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RltvGgarQxG5"
      },
      "outputs": [],
      "source": [
        "# Mohammed Ahmed Zakiuddin\n",
        "# 1001675091\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier():\n",
        "  '''\n",
        "  Bayes Theorem Formula\n",
        "  P(Y|X) = P(X|Y) * P(Y) / P(X)\n",
        "  '''\n",
        "\n",
        "  def calc_prior(self, features, target):\n",
        "    '''\n",
        "    prior probability P(y)\n",
        "    '''\n",
        "\n",
        "    self.prior = (features.groupby(target).apply(lambda x: len(x))/self.rows).to_numpy()\n",
        "    return self.prior\n",
        "  \n",
        "  def calc_stats(self, features, target):\n",
        "    '''\n",
        "    calc mean, variance  for each column\n",
        "    '''\n",
        "    self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
        "    self.var = features.groupby(target).apply(np.var).to_numpy()\n",
        "\n",
        "    self.mean += 0.01\n",
        "    self.var += 0.01\n",
        "\n",
        "    return self.mean, self.var\n",
        "\n",
        "  def calc_posterior(self, x):\n",
        "\n",
        "    # Calculating the posterior probability for each class\n",
        "\n",
        "    posterior = []\n",
        "    for i in range(self.count):\n",
        "      prior = np.log(self.prior[i])\n",
        "      conditional = np.sum(np.log(self.gaussian_den(i, x)))\n",
        "      post = prior + conditional\n",
        "      posterior.append(post)\n",
        "    \n",
        "    return self.class_target[np.argmax(posterior)]\n",
        "  \n",
        "  def gaussian_den(self, class_idx, x):\n",
        "\n",
        "    # Calculate the probability from the gaussian density function (normal dis)\n",
        "\n",
        "    mean = self.mean[class_idx]\n",
        "    var = self.var[class_idx]\n",
        "    numerator = np.exp((-1/2)*((x-mean)**2)/(2*var))\n",
        "    den = np.sqrt(2* np.pi *var)\n",
        "    prob = numerator/den\n",
        "    return prob\n",
        "    \n",
        "  def fit(self, features, target):\n",
        "\n",
        "    self.class_target = np.unique(target)\n",
        "    self.count = len(self.class_target)  \n",
        "    self.feature_num = features.shape[1]\n",
        "    self.rows = features.shape[0] \n",
        "    self.calc_stats(features, target)\n",
        "    self.calc_prior(features, target)\n",
        "\n",
        "  def predict(self, features):\n",
        "    predictions = [self.calc_posterior(f) for f in features.to_numpy()]\n",
        "    return predictions\n",
        "  \n",
        "  def accuracy(self, y_test, y_pred):\n",
        "    accuracy = np.sum(y_test == y_pred)/len(y_test)\n",
        "    return accuracy \n",
        "  "
      ],
      "metadata": {
        "id": "UgAcxwRrQ64s"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_prior(features, target):\n",
        "\n",
        "    '''\n",
        "    prior probability P(y)\n",
        "    '''\n",
        "    rows = features.shape[0]\n",
        "    prior = (features.groupby(target).apply(lambda x: len(x))/rows).to_numpy()\n",
        "    return prior\n",
        "\n",
        "features = []\n",
        "target = []\n",
        "\n",
        "with open(\"customerReviews.txt\") as file_input:\n",
        "    for line in file_input.readlines():\n",
        "        t = line.split(\",\")[-1].split()[0]\n",
        "        f = ' '.join(line.split(\",\")[:-1])\n",
        "        features.append(f)\n",
        "        target.append(t)\n",
        "\n",
        "df = pd.DataFrame(list(zip(features, target)), columns=['Reviews', 'Target'])\n",
        "\n",
        "Review, Label = df.iloc[:, 0], df.iloc[:,-1]\n",
        "\n",
        "check = CountVectorizer()\n",
        "Review = check.fit_transform(Review)\n",
        "\n",
        "Review = pd.DataFrame(Review.toarray(), columns = check.get_feature_names_out())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Review, Label, test_size = 0.3, random_state = 0)\n",
        "\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "\n",
        "# Convert the DataFrame to a list of tuples this is a dictionary\n",
        "data = list(df.to_records(index=False))\n",
        "\n",
        "# Separated the sentences and labels into separate lists\n",
        "sentences = [d[0] for d in data]\n",
        "labels = [d[1] for d in data]\n",
        "\n",
        "# Split the sentences into words\n",
        "words = [sentence.split() for sentence in sentences]\n",
        "\n",
        "pos_word_freq = {}\n",
        "neg_word_freq = {}\n",
        "\n",
        "# First checks whether the label of the review is positive or negative.\n",
        "# Then, loops through each word in the review and update the corresponding dictionary with the frequency count for that word. \n",
        "# If the word is not already in the dictionary, you add it with a count of 1.\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  if labels[i] == 'positive':\n",
        "    # process positive reviews\n",
        "    for word in words[i]:\n",
        "      if word in pos_word_freq:\n",
        "        pos_word_freq[word] += 1\n",
        "      else:\n",
        "        pos_word_freq[word] = 1\n",
        "  elif labels[i] == 'negative':\n",
        "    #process negative reviews\n",
        "    for word in words[i]:\n",
        "      if word in neg_word_freq:\n",
        "        neg_word_freq[word] += 1\n",
        "      else:\n",
        "        neg_word_freq[word] = 1\n",
        "\n",
        "print('Top 10 most frequent words in positive reviews:')\n",
        "sorted_pos_word_freq = sorted(pos_word_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, freq in sorted_pos_word_freq[:10]:\n",
        "    print(f'{word}: {freq}')\n",
        "\n",
        "print('Top 10 most frequent words in negative reviews:')\n",
        "sorted_neg_word_freq = sorted(neg_word_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, freq in sorted_neg_word_freq[:10]:\n",
        "    print(f'{word}: {freq}')\n",
        "\n",
        "\n",
        "# Calculate the probability of each word given that it is positive and given that it is negative\n",
        "total_positive_words = sum(pos_word_freq.values())\n",
        "total_negative_words = sum(neg_word_freq.values())\n",
        "positive_probabilities = {word: count/total_positive_words for word, count in pos_word_freq.items()}\n",
        "negative_probabilities = {word: count/total_negative_words for word, count in neg_word_freq.items()}\n",
        "\n",
        "# Accumulate the probabilities for each label\n",
        "positive_probability_sum = 0\n",
        "negative_probability_sum = 0\n",
        "\n",
        "prior = calc_prior(Review, Label)\n",
        "\n",
        "likelyhood = []\n",
        "\n",
        "prior_positive = 1\n",
        "prior_negative = 1\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  sentence_probability_positive = 1\n",
        "  sentence_probability_negative = 1\n",
        "\n",
        "  for word in X_test.iloc[i]:\n",
        "    if word in positive_probabilities:\n",
        "      sentence_probability_positive *= positive_probabilities[word]\n",
        "    if word in negative_probabilities:\n",
        "      sentence_probability_negative *= negative_probabilities[word]\n",
        "\n",
        "  prior_positive *= sentence_probability_positive\n",
        "  prior_negative *= sentence_probability_negative\n",
        "\n",
        "  if prior_positive > prior_negative:\n",
        "    likelyhood.append(prior_positive)\n",
        "  else:\n",
        "    likelyhood.append(prior_negative)\n",
        "\n",
        "def accuracy(y_test, y_pred):\n",
        "\n",
        "  y_test_num = y_test.replace({'positive': 1, 'negative': 0})\n",
        "  y_pred_num = pd.Series(likelyhood).apply(lambda x: 1 if x > 0.5 else 0)\n",
        "  accurate = np.sum(y_test_num == y_pred_num) / len(y_test_num)\n",
        "\n",
        "result = accuracy(y_test, likelyhood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBgH-rGEIIiq",
        "outputId": "387faf50-e0f5-4a0f-954f-6ea5205ecf21"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most frequent words in positive reviews:\n",
            "service: 32\n",
            "is: 26\n",
            "I: 24\n",
            "product: 24\n",
            "this: 23\n",
            "This: 21\n",
            "a: 18\n",
            "The: 18\n",
            "I'm: 14\n",
            "with: 13\n",
            "Top 10 most frequent words in negative reviews:\n",
            "The: 57\n",
            "service: 41\n",
            "is: 41\n",
            "product: 26\n",
            "not: 26\n",
            "as: 24\n",
            "a: 17\n",
            "was: 16\n",
            "I: 11\n",
            "to: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NB = NaiveBayesClassifier()\n",
        "\n",
        "NB.fit(X_train, y_train)\n",
        "\n",
        "# 3. Using the trained classifier to predict the sentiment of each review in the test set.\n",
        "predictions = NB.predict(X_test)\n",
        "\n",
        "# 4. Computes the accuracy of the classifier\n",
        "print(NB.accuracy(y_test, predictions))\n",
        "\n",
        "predict = {'I had a terrible experience with this company', 'This is a great company with excellent customer service', 'I was really disappointed with this product', 'The service is too expensive for what it offers'}\n",
        "\n",
        "transformed_data = check.transform(predict)\n",
        "predict_df = pd.DataFrame(transformed_data.toarray(), columns = check.get_feature_names_out())\n",
        "predictions = NB.predict(predict_df)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzcbtGjpUXWR",
        "outputId": "8a9c7f09-f1ba-4a47-8c51-804a8554f06e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9069767441860465\n",
            "['negative', 'positive', 'positive', 'negative']\n"
          ]
        }
      ]
    }
  ]
}